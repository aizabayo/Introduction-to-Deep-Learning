{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e62b72",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a0234",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# UTTERANCE TO PHONEME MAPPING \n",
    "\n",
    "For this assignment we explore the mapping of spoken utterances to their corresponding phonemes. Which is a crucial step in Automatic Speech Recognition (ASR) systems, where the goal is to convert audio signals into a sequence of phonemes, which can then be used to reconstruct the original text.\n",
    "\n",
    "For this assignment I used the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddfd07e",
   "metadata": {
    "id": "UR4qfYrVoO4v",
    "papermill": {
     "duration": 0.01757,
     "end_time": "2024-11-08T19:51:11.548879",
     "exception": false,
     "start_time": "2024-11-08T19:51:11.531309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdbd03e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:51:11.581618Z",
     "iopub.status.busy": "2024-11-08T19:51:11.581282Z",
     "iopub.status.idle": "2024-11-08T19:52:57.192224Z",
     "shell.execute_reply": "2024-11-08T19:52:57.191072Z"
    },
    "id": "mA9qZoIDcx-h",
    "papermill": {
     "duration": 105.629607,
     "end_time": "2024-11-08T19:52:57.194427",
     "exception": false,
     "start_time": "2024-11-08T19:51:11.564820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75528f46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:52:57.227516Z",
     "iopub.status.busy": "2024-11-08T19:52:57.226970Z",
     "iopub.status.idle": "2024-11-08T19:53:20.322910Z",
     "shell.execute_reply": "2024-11-08T19:53:20.321960Z"
    },
    "papermill": {
     "duration": 23.114879,
     "end_time": "2024-11-08T19:53:20.325235",
     "exception": false,
     "start_time": "2024-11-08T19:52:57.210356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==69.5.1\r\n",
      "  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Downloading setuptools-69.5.1-py3-none-any.whl (894 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: setuptools\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 70.0.0\r\n",
      "    Uninstalling setuptools-70.0.0:\r\n",
      "      Successfully uninstalled setuptools-70.0.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "conda 24.9.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\r\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 1.13.1+cu117 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed setuptools-69.5.1\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade setuptools wheel\n",
    "!pip install setuptools==69.5.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc8dadd",
   "metadata": {
    "id": "ONgAWhqdoYy-",
    "papermill": {
     "duration": 0.016177,
     "end_time": "2024-11-08T19:53:20.358216",
     "exception": false,
     "start_time": "2024-11-08T19:53:20.342039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "This may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a451de26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:53:20.392161Z",
     "iopub.status.busy": "2024-11-08T19:53:20.391816Z",
     "iopub.status.idle": "2024-11-08T19:56:16.958627Z",
     "shell.execute_reply": "2024-11-08T19:56:16.957553Z"
    },
    "id": "SS7a7xeEoaV9",
    "papermill": {
     "duration": 176.606787,
     "end_time": "2024-11-08T19:56:16.981150",
     "exception": false,
     "start_time": "2024-11-08T19:53:20.374363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummaryX==1.3.0\r\n",
      "  Downloading torchsummaryX-1.3.0-py3-none-any.whl.metadata (325 bytes)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchsummaryX==1.3.0) (1.13.1+cu117)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchsummaryX==1.3.0) (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from torchsummaryX==1.3.0) (2.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->torchsummaryX==1.3.0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->torchsummaryX==1.3.0) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->torchsummaryX==1.3.0) (2024.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchsummaryX==1.3.0) (4.12.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->torchsummaryX==1.3.0) (1.16.0)\r\n",
      "Downloading torchsummaryX-1.3.0-py3-none-any.whl (3.6 kB)\r\n",
      "Installing collected packages: torchsummaryX\r\n",
      "Successfully installed torchsummaryX-1.3.0\r\n",
      "Collecting pandas==1.5.2\r\n",
      "  Downloading pandas-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.2) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.2) (2024.1)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.2) (1.26.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.5.2) (1.16.0)\r\n",
      "Downloading pandas-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pandas\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.2\r\n",
      "    Uninstalling pandas-2.2.2:\r\n",
      "      Successfully uninstalled pandas-2.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 24.8.3 requires cubinlinker, which is not installed.\r\n",
      "cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 24.8.3 requires ptxcompiler, which is not installed.\r\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\r\n",
      "cudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.2 which is incompatible.\r\n",
      "dask-cudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.2 which is incompatible.\r\n",
      "dask-expr 1.1.15 requires pandas>=2, but you have pandas 1.5.2 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.2 which is incompatible.\r\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.2 which is incompatible.\r\n",
      "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.2 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.2 which is incompatible.\r\n",
      "rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\r\n",
      "woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.2 which is incompatible.\r\n",
      "xarray 2024.9.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.2 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed pandas-1.5.2\r\n",
      "Cloning into 'ctcdecode'...\r\n",
      "remote: Enumerating objects: 1102, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\r\n",
      "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (1102/1102), 782.27 KiB | 11.17 MiB/s, done.\r\n",
      "Resolving deltas: 100% (529/529), done.\r\n",
      "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\r\n",
      "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\r\n",
      "Cloning into '/kaggle/working/ctcdecode/third_party/ThreadPool'...\r\n",
      "remote: Enumerating objects: 82, done.        \r\n",
      "remote: Counting objects: 100% (26/26), done.        \r\n",
      "remote: Compressing objects: 100% (9/9), done.        \r\n",
      "remote: Total 82 (delta 19), reused 17 (delta 17), pack-reused 56 (from 1)        \r\n",
      "Receiving objects: 100% (82/82), 13.34 KiB | 13.34 MiB/s, done.\r\n",
      "Resolving deltas: 100% (36/36), done.\r\n",
      "Cloning into '/kaggle/working/ctcdecode/third_party/kenlm'...\r\n",
      "remote: Enumerating objects: 14170, done.        \r\n",
      "remote: Counting objects: 100% (483/483), done.        \r\n",
      "remote: Compressing objects: 100% (337/337), done.        \r\n",
      "remote: Total 14170 (delta 167), reused 410 (delta 132), pack-reused 13687 (from 1)        \r\n",
      "Receiving objects: 100% (14170/14170), 5.91 MiB | 12.23 MiB/s, done.\r\n",
      "Resolving deltas: 100% (8047/8047), done.\r\n",
      "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\r\n",
      "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\r\n",
      "/kaggle/working/ctcdecode\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummaryX==1.3.0\n",
    "!pip install pandas==1.5.2\n",
    "!pip install wandb --quiet\n",
    "!pip install python-Levenshtein -q\n",
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!pip install wget -q\n",
    "%cd ctcdecode\n",
    "!pip install . -q\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b73c52",
   "metadata": {
    "id": "IWVONJxCobPc",
    "papermill": {
     "duration": 0.020127,
     "end_time": "2024-11-08T19:56:17.022630",
     "exception": false,
     "start_time": "2024-11-08T19:56:17.002503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67530a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:17.064803Z",
     "iopub.status.busy": "2024-11-08T19:56:17.064400Z",
     "iopub.status.idle": "2024-11-08T19:56:20.266521Z",
     "shell.execute_reply": "2024-11-08T19:56:20.265429Z"
    },
    "id": "78ZTCIXoof2f",
    "papermill": {
     "duration": 3.225672,
     "end_time": "2024-11-08T19:56:20.268577",
     "exception": false,
     "start_time": "2024-11-08T19:56:17.042905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummaryX import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import torchaudio.transforms as tat\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# imports for decoding and distance calculation\n",
    "import ctcdecode\n",
    "import Levenshtein\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c279fa4",
   "metadata": {
    "id": "gg3-yJ8tok34",
    "papermill": {
     "duration": 0.020323,
     "end_time": "2024-11-08T19:56:20.309548",
     "exception": false,
     "start_time": "2024-11-08T19:56:20.289225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kaggle Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73cfb481",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:20.351406Z",
     "iopub.status.busy": "2024-11-08T19:56:20.350972Z",
     "iopub.status.idle": "2024-11-08T19:56:26.728548Z",
     "shell.execute_reply": "2024-11-08T19:56:26.727332Z"
    },
    "id": "AdUelfGhom1m",
    "papermill": {
     "duration": 6.401106,
     "end_time": "2024-11-08T19:56:26.730842",
     "exception": false,
     "start_time": "2024-11-08T19:56:20.329736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8 -q\n",
    "!mkdir /root/.kaggle\n",
    "\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
    "    f.write('{\"username\":\"angeizabayo\",\"key\":\"6727c97821f5c0aae21046c561c0545d\"}') # TODO: Put your kaggle username & key here\n",
    "\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13f1f3d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:26.774054Z",
     "iopub.status.busy": "2024-11-08T19:56:26.773253Z",
     "iopub.status.idle": "2024-11-08T19:56:26.777727Z",
     "shell.execute_reply": "2024-11-08T19:56:26.776900Z"
    },
    "id": "dSjBwfXeoq4B",
    "papermill": {
     "duration": 0.028204,
     "end_time": "2024-11-08T19:56:26.779756",
     "exception": false,
     "start_time": "2024-11-08T19:56:26.751552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c 11-785-hw3p2-f24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ab8f40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:26.821456Z",
     "iopub.status.busy": "2024-11-08T19:56:26.820982Z",
     "iopub.status.idle": "2024-11-08T19:56:26.824674Z",
     "shell.execute_reply": "2024-11-08T19:56:26.823862Z"
    },
    "id": "_ruxWP60LCQA",
    "papermill": {
     "duration": 0.02655,
     "end_time": "2024-11-08T19:56:26.826539",
     "exception": false,
     "start_time": "2024-11-08T19:56:26.799989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# '''\n",
    "# This will take a couple minutes, but you should see at least the following:\n",
    "# 11-785-f24-hw3p2  ctcdecode  hw3p2asr-f24.zip  sample_data\n",
    "# '''\n",
    "# !unzip -q 11-785-hw3p2-f24.zip\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a7282",
   "metadata": {
    "id": "R9v5ewZDMpYA",
    "papermill": {
     "duration": 0.019959,
     "end_time": "2024-11-08T19:56:26.867507",
     "exception": false,
     "start_time": "2024-11-08T19:56:26.847548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af0e191e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:26.909320Z",
     "iopub.status.busy": "2024-11-08T19:56:26.908761Z",
     "iopub.status.idle": "2024-11-08T19:56:26.912240Z",
     "shell.execute_reply": "2024-11-08T19:56:26.911425Z"
    },
    "id": "4Cp-716IMZRd",
    "papermill": {
     "duration": 0.026407,
     "end_time": "2024-11-08T19:56:26.914106",
     "exception": false,
     "start_time": "2024-11-08T19:56:26.887699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fbc3e",
   "metadata": {
    "id": "2ORNHnSFroP0",
    "papermill": {
     "duration": 0.020382,
     "end_time": "2024-11-08T19:56:26.954697",
     "exception": false,
     "start_time": "2024-11-08T19:56:26.934315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5fa74",
   "metadata": {},
   "source": [
    "Given CMU ARPAbet dictionary which maps ARPABET phoneme to their corresponding single chatacter used in our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa33d7ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1584fcb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:26.996718Z",
     "iopub.status.busy": "2024-11-08T19:56:26.996010Z",
     "iopub.status.idle": "2024-11-08T19:56:27.003773Z",
     "shell.execute_reply": "2024-11-08T19:56:27.003055Z"
    },
    "id": "k0v7wHRWrqH6",
    "papermill": {
     "duration": 0.030635,
     "end_time": "2024-11-08T19:56:27.005524",
     "exception": false,
     "start_time": "2024-11-08T19:56:26.974889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ARPABET PHONEME MAPPING\n",
    "# DO NOT CHANGE\n",
    "\n",
    "CMUdict_ARPAbet = {\n",
    "    \"\" : \" \",\n",
    "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\",\n",
    "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\",\n",
    "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n",
    "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\",\n",
    "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\",\n",
    "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\",\n",
    "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\",\n",
    "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
    "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
    "}\n",
    "\n",
    "CMUdict = list(CMUdict_ARPAbet.keys())\n",
    "ARPAbet = list(CMUdict_ARPAbet.values())\n",
    "\n",
    "\n",
    "PHONEMES = CMUdict[:-2]\n",
    "LABELS = ARPAbet[:-2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2638c021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:27.047415Z",
     "iopub.status.busy": "2024-11-08T19:56:27.046811Z",
     "iopub.status.idle": "2024-11-08T19:56:27.050501Z",
     "shell.execute_reply": "2024-11-08T19:56:27.049664Z"
    },
    "id": "eN2kcxwXLLBb",
    "papermill": {
     "duration": 0.026545,
     "end_time": "2024-11-08T19:56:27.052373",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.025828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You might want to play around with the mapping as a sanity check here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b6552",
   "metadata": {
    "id": "agmNBKf4JrLV",
    "papermill": {
     "duration": 0.02005,
     "end_time": "2024-11-08T19:56:27.093038",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.072988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c7997",
   "metadata": {},
   "source": [
    "Given AudioDataset Class to handles the loading, processing, and batching of speech data for phoneme recognition model. Where loads MFCC features and phoneme transcripts, provides methods for accessing individual data samples, and implements collate_fn method for efficient batch processing with padding and potential transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db065a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:27.134832Z",
     "iopub.status.busy": "2024-11-08T19:56:27.134483Z",
     "iopub.status.idle": "2024-11-08T19:56:27.148643Z",
     "shell.execute_reply": "2024-11-08T19:56:27.147841Z"
    },
    "id": "afd0_vlbJmr_",
    "papermill": {
     "duration": 0.037297,
     "end_time": "2024-11-08T19:56:27.150509",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.113212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    # For this homework, we give you full flexibility to design your data set class.\n",
    "    # Hint: The data from HW1 is very similar to this HW\n",
    "\n",
    "    #TODO\n",
    "    def __init__(self,directory,partition):\n",
    "        '''\n",
    "        Initializes the dataset.\n",
    "\n",
    "        INPUTS: What inputs do you need here?\n",
    "        '''\n",
    "        self.mfcc_dir       =  os.path.join(directory, partition,'mfcc')\n",
    "        self.transcript_dir = os.path.join(directory,partition,'transcript')\n",
    "\n",
    "        self.mfcc_files          = sorted(os.listdir(self.mfcc_dir))\n",
    "        self.transcript_files    = sorted(os.listdir(self.transcript_dir))\n",
    "\n",
    "\n",
    "        self.PHONEMES = PHONEMES\n",
    "\n",
    "        assert len(self.mfcc_files) == len(self.transcript_files)\n",
    "\n",
    "        self.mfccs= []\n",
    "        self.transcripts  = []\n",
    "\n",
    "        for file in self.mfcc_files:\n",
    "            files = np.load(os.path.join(self.mfcc_dir, file))\n",
    "            self.mfccs.append((files))\n",
    "        for file in self.transcript_files:\n",
    "            files = np.load(os.path.join(self.transcript_dir, file))\n",
    "            transcripts = files[1:-1]\n",
    "            self.transcripts.append(np.array([self.PHONEMES.index(i) for i in transcripts]))\n",
    "\n",
    "\n",
    "        #TODO\n",
    "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
    "        self.length = len(self.mfccs)\n",
    "\n",
    "        '''\n",
    "        You may decide to do this in __getitem__ if you wish.\n",
    "        However, doing this here will make the __init__ function take the load of\n",
    "        loading the data, and shift it away from training.\n",
    "        '''\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        '''\n",
    "        TODO: What do we return here?\n",
    "        '''\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        '''\n",
    "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
    "\n",
    "        If you didn't do the loading and processing of the data in __init__,\n",
    "        do that here.\n",
    "\n",
    "        Once done, return a tuple of features and labels.\n",
    "        '''\n",
    "\n",
    "        mfcc = torch.FloatTensor(self.mfccs[ind])\n",
    "        transcript = torch.LongTensor(self.transcripts[ind])\n",
    "\n",
    "        return mfcc, transcript\n",
    "\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        '''\n",
    "        TODO:\n",
    "        1.  Extract the features and labels from 'batch'\n",
    "        2.  We will additionally need to pad both features and labels,\n",
    "            look at pytorch's docs for pad_sequence\n",
    "        3.  This is a good place to perform transforms, if you so wish.\n",
    "            Performing them on batches will speed the process up a bit.\n",
    "        4.  Return batch of features, labels, lenghts of features,\n",
    "            and lengths of labels.\n",
    "        '''\n",
    "        # batch of input mfcc coefficients\n",
    "        batch_mfcc = [i[0] for i in batch]\n",
    "        # batch of output phonemes\n",
    "        batch_transcript = [i[1] for i in batch]\n",
    "\n",
    "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
    "        # Also be sure to check the input format (batch_first)\n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True)\n",
    "        lengths_mfcc = [len(i) for i in batch_mfcc]\n",
    "\n",
    "        batch_transcript_pad = pad_sequence(batch_transcript, batch_first = True) # TODO\n",
    "        lengths_transcript = [len(i) for i  in batch_transcript]\n",
    "\n",
    "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
    "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
    "        #                  -> Would we apply transformation on the validation set as well?\n",
    "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
    "\n",
    "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
    "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802a24da",
   "metadata": {
    "id": "hqDrxeHfJw4g",
    "papermill": {
     "duration": 0.019979,
     "end_time": "2024-11-08T19:56:27.190797",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.170818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939af67f",
   "metadata": {},
   "source": [
    " AudioDatasetTest Class designed to manage the test dataset for our speech recognition model. Where it loads only the MFCC features from the specified directory, as the test set does not include labels. It includes methods for accessing test samples and a  collate_fn method to handle padding and potential data transformations during the batching process, crucial for consistent input to the model during inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabb102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:27.232530Z",
     "iopub.status.busy": "2024-11-08T19:56:27.232015Z",
     "iopub.status.idle": "2024-11-08T19:56:27.241245Z",
     "shell.execute_reply": "2024-11-08T19:56:27.240418Z"
    },
    "id": "HrLS1wfVJppA",
    "papermill": {
     "duration": 0.032207,
     "end_time": "2024-11-08T19:56:27.243175",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.210968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Dataloader\n",
    "#TODO\n",
    "class AudioDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self,directory,partition):\n",
    "        '''\n",
    "        Initializes the dataset.\n",
    "\n",
    "        INPUTS: What inputs do you need here?\n",
    "        '''\n",
    "\n",
    "        self.mfcc_dir  =  os.path.join(directory, partition,'mfcc')\n",
    "        self.mfcc_files  = sorted(os.listdir(self.mfcc_dir)) #NotImplemented\n",
    "        self.PHONEMES = PHONEMES\n",
    "\n",
    "        self.mfccs = []\n",
    "\n",
    "        for files in self.mfcc_files:\n",
    "            file_path = np.load(os.path.join(self.mfcc_dir,files))\n",
    "            self.mfccs.append(file_path)\n",
    "\n",
    "        self.length = len(self.mfcc_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        '''\n",
    "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
    "\n",
    "        If you didn't do the loading and processing of the data in __init__,\n",
    "        do that here.\n",
    "\n",
    "        Once done, return a tuple of features and labels.\n",
    "        '''\n",
    "        mfcc = torch.FloatTensor(self.mfccs[ind])\n",
    "\n",
    "        return mfcc\n",
    "\n",
    "\n",
    "    def collate_fn(self,batch):\n",
    "        '''\n",
    "        TODO:\n",
    "        1.  Extract the features and labels from 'batch'\n",
    "        2.  We will additionally need to pad both features and labels,\n",
    "          look at pytorch's docs for pad_sequence\n",
    "        3.  This is a good place to perform transforms, if you so wish.\n",
    "          Performing them on batches will speed the process up a bit.\n",
    "        4.  Return batch of features, labels, lenghts of features,\n",
    "          and lengths of labels.\n",
    "        '''\n",
    "        batch_mfcc = batch\n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True)\n",
    "        lengths_mfcc = [len(i) for i in batch_mfcc]\n",
    "\n",
    "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
    "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
    "        #                  -> Would we apply transformation on the validation set as well?\n",
    "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
    "\n",
    "        # Return the following values: padded features, actual length of features\n",
    "        return batch_mfcc_pad, torch.tensor(lengths_mfcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6dcbf",
   "metadata": {
    "id": "Pt-veYcdL6Fe",
    "papermill": {
     "duration": 0.020088,
     "end_time": "2024-11-08T19:56:27.284839",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.264751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Config - Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a4e5e",
   "metadata": {},
   "source": [
    "updated config dictionary for saving the hyperparameters used in Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cd5ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:27.326570Z",
     "iopub.status.busy": "2024-11-08T19:56:27.326026Z",
     "iopub.status.idle": "2024-11-08T19:56:27.330714Z",
     "shell.execute_reply": "2024-11-08T19:56:27.329891Z"
    },
    "id": "MN82c3KpLup8",
    "papermill": {
     "duration": 0.027596,
     "end_time": "2024-11-08T19:56:27.332508",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.304912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feel free to add more items here\n",
    "config = {\n",
    "    \"beam_width\" : 2,\n",
    "    \"lr\"         : 1e-3,\n",
    "    \"epochs\"     : 50,\n",
    "    \"batch_size\" : 64,\n",
    "    'directory': '/kaggle/input/11-785-hw3p2-f24/11785-f24-hw3p2',\n",
    "}\n",
    "\n",
    "# You may pass this as a parameter to the dataset class above\n",
    "# This will help modularize your implementation\n",
    "transforms = [] # set of tranformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c541732",
   "metadata": {
    "id": "NmuPk9J6L8dz",
    "papermill": {
     "duration": 0.019865,
     "end_time": "2024-11-08T19:56:27.372474",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.352609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d038e623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:27.414082Z",
     "iopub.status.busy": "2024-11-08T19:56:27.413805Z",
     "iopub.status.idle": "2024-11-08T19:56:27.526139Z",
     "shell.execute_reply": "2024-11-08T19:56:27.525262Z"
    },
    "papermill": {
     "duration": 0.135252,
     "end_time": "2024-11-08T19:56:27.528163",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.392911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get me RAMMM!!!!\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec303b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T19:56:27.570899Z",
     "iopub.status.busy": "2024-11-08T19:56:27.570213Z",
     "iopub.status.idle": "2024-11-08T20:10:55.213952Z",
     "shell.execute_reply": "2024-11-08T20:10:55.212991Z"
    },
    "id": "4mzoYfTKu14s",
    "papermill": {
     "duration": 867.689576,
     "end_time": "2024-11-08T20:10:55.238431",
     "exception": false,
     "start_time": "2024-11-08T19:56:27.548855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size:  64\n",
      "Train dataset samples = 28539, batches = 446\n",
      "Val dataset samples = 2703, batches = 43\n",
      "Test dataset samples = 2620, batches = 41\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_data = AudioDataset(directory = config['directory'], partition='train-clean-100')\n",
    "val_data = AudioDataset(directory= config['directory'], partition='dev-clean')\n",
    "test_data = AudioDatasetTest(directory=config['directory'], partition='test-clean')\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_data,\n",
    "    num_workers=2,\n",
    "    batch_size =config['batch_size'],\n",
    "    pin_memory=True, shuffle=True,\n",
    "    collate_fn= train_data.collate_fn\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_data,\n",
    "    num_workers=2,\n",
    "    batch_size =config['batch_size'],\n",
    "    pin_memory=True, \n",
    "    shuffle=True,\n",
    "    collate_fn= val_data.collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_data,\n",
    "    num_workers=1,\n",
    "    batch_size =config['batch_size'],\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    collate_fn= test_data.collate_fn\n",
    ")\n",
    "\n",
    "print(\"Batch size: \", config['batch_size'])\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db94f539",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:55.282253Z",
     "iopub.status.busy": "2024-11-08T20:10:55.281367Z",
     "iopub.status.idle": "2024-11-08T20:10:56.787048Z",
     "shell.execute_reply": "2024-11-08T20:10:56.785668Z"
    },
    "id": "cXMtwyviKaxK",
    "papermill": {
     "duration": 1.530297,
     "end_time": "2024-11-08T20:10:56.789405",
     "exception": false,
     "start_time": "2024-11-08T20:10:55.259108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1683, 28]) torch.Size([64, 221]) torch.Size([64]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "for data in train_loader:\n",
    "    x, y, lx, ly = data\n",
    "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a0578",
   "metadata": {
    "id": "wSexxhdfMUzx",
    "papermill": {
     "duration": 0.020697,
     "end_time": "2024-11-08T20:10:56.883222",
     "exception": false,
     "start_time": "2024-11-08T20:10:56.862525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144bdcc",
   "metadata": {
    "id": "HLad4pChcuvX",
    "papermill": {
     "duration": 0.020863,
     "end_time": "2024-11-08T20:10:56.924804",
     "exception": false,
     "start_time": "2024-11-08T20:10:56.903941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Basic\n",
    "\n",
    "This is a basic block for understanding, you can skip this and move to pBLSTM one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da09718",
   "metadata": {},
   "source": [
    "I did not use this basic block as it was suggested so I jumped straight to pBLSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602672a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:56.968579Z",
     "iopub.status.busy": "2024-11-08T20:10:56.968272Z",
     "iopub.status.idle": "2024-11-08T20:10:56.973471Z",
     "shell.execute_reply": "2024-11-08T20:10:56.972582Z"
    },
    "id": "EQhvHr71GJfq",
    "papermill": {
     "duration": 0.029148,
     "end_time": "2024-11-08T20:10:56.975397",
     "exception": false,
     "start_time": "2024-11-08T20:10:56.946249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# class Network(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "\n",
    "#         super(Network, self).__init__()\n",
    "\n",
    "#         # Adding some sort of embedding layer or feature extractor might help performance.\n",
    "#         # self.embedding = ?\n",
    "\n",
    "#         # TODO : look up the documentation. You might need to pass some additional parameters.\n",
    "#         self.lstm = nn.LSTM(input_size = __, hidden_size = 256, num_layers = 1)\n",
    "\n",
    "#         self.classification = nn.Sequential(\n",
    "#             #TODO: Linear layer with in_features from the lstm module above and out_features = OUT_SIZE\n",
    "#         )\n",
    "\n",
    "\n",
    "#         self.logSoftmax = #TODO: Apply a log softmax here. Which dimension would apply it on ?\n",
    "\n",
    "#     def forward(self, x, lx):\n",
    "#         #TODO\n",
    "#         # The forward function takes 2 parameter inputs here. Why?\n",
    "#         # Refer to the handout for hints\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe8fa8",
   "metadata": {
    "id": "tUThsowyQdN7",
    "papermill": {
     "duration": 0.020543,
     "end_time": "2024-11-08T20:10:57.066684",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.046141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialize Basic Network\n",
    "(If trying out the basic Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa1532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model = Network().to(device)\n",
    "# summary(model, x.to(device), lx) # x and lx come from the sanity check above :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab23dce",
   "metadata": {
    "id": "e-qb7wnAzCZl",
    "papermill": {
     "duration": 0.020643,
     "end_time": "2024-11-08T20:10:57.108020",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.087377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ASR Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb565fc",
   "metadata": {
    "id": "PB6eh3gnMUzy",
    "papermill": {
     "duration": 0.020351,
     "end_time": "2024-11-08T20:10:57.149016",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.128665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Pyramid Bi-LSTM (pBLSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b418a",
   "metadata": {},
   "source": [
    " Pyramid BI-LSTM(pBLSTM) with PermuteBlock for transposing tensor dimensions and pBLSTM\n",
    " A custom Pyramidal BiLSTM module designed to process sequences by reducing their time resolution while doubling the feature dimension, facilitating deeper and more efficient sequence modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6818e926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:57.193218Z",
     "iopub.status.busy": "2024-11-08T20:10:57.192880Z",
     "iopub.status.idle": "2024-11-08T20:10:57.197771Z",
     "shell.execute_reply": "2024-11-08T20:10:57.196885Z"
    },
    "id": "qd4BEX_yMUzz",
    "papermill": {
     "duration": 0.030213,
     "end_time": "2024-11-08T20:10:57.199729",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.169516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utils for network\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "class PermuteBlock(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1238d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:57.242490Z",
     "iopub.status.busy": "2024-11-08T20:10:57.241923Z",
     "iopub.status.idle": "2024-11-08T20:10:57.252220Z",
     "shell.execute_reply": "2024-11-08T20:10:57.251458Z"
    },
    "id": "OmdyXI6KMUzz",
    "papermill": {
     "duration": 0.033755,
     "end_time": "2024-11-08T20:10:57.254160",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.220405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class pBLSTM(torch.nn.Module):\n",
    "\n",
    "    '''\n",
    "    Pyramidal BiLSTM\n",
    "    Read the write up/paper and understand the concepts and then write your implementation here.\n",
    "\n",
    "    At each step,\n",
    "    1. Pad your input if it is packed (Unpack it)\n",
    "    2. Reduce the input length dimension by concatenating feature dimension\n",
    "        (Tip: Write down the shapes and understand)\n",
    "        (i) How should  you deal with odd/even length input?\n",
    "        (ii) How should you deal with input length array (x_lens) after truncating the input?\n",
    "    3. Pack your input\n",
    "    4. Pass it into LSTM layer\n",
    "\n",
    "    To make our implementation modular, we pass 1 layer at a time.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(pBLSTM, self).__init__()\n",
    "\n",
    "        self.blstm = nn.LSTM(input_size=input_size*2, hidden_size=hidden_size, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        # TODO: Initialize a single layer bidirectional LSTM with the given input_size and hidden_size\n",
    "\n",
    "    def forward(self, x_packed): # x_packed is a PackedSequence\n",
    "\n",
    "        \n",
    "        x, x_lens = pad_packed_sequence(x_packed, batch_first=True) # TODO: Pad Packed Sequence\n",
    "\n",
    "        # Call self.trunc_reshape() which downsamples the time steps of x and increases the feature dimensions as mentioned above\n",
    "        x, x_lens = self.trunc_reshape(x, x_lens)\n",
    "\n",
    "        # self.trunc_reshape will return 2 outputs. What are they? Think about what quantites are changing.\n",
    "        # TODO: Pack Padded Sequence. What output(s) would you get?\n",
    "        x_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "\n",
    "        # TODO: Pass the sequence through bLSTM\n",
    "        x_packed, _ = self.blstm(x_packed)\n",
    "\n",
    "        # What do you return?\n",
    "\n",
    "        return x_packed\n",
    "\n",
    "    def trunc_reshape(self, x, x_lens):\n",
    "        # TODO: If you have odd number of timesteps, how can you handle it? (Hint: You can exclude them)\n",
    "        # TODO: Reshape x. When reshaping x, you have to reduce number of timesteps by a downsampling factor while increasing number of features by the same factor\n",
    "        # TODO: Reduce lengths by the same downsampling factor\n",
    "\n",
    "        batch_size, timesteps, features = x.shape\n",
    "\n",
    "        # If there is an odd number of timesteps, exclude the last timestep\n",
    "        if timesteps % 2 != 0:\n",
    "            x = x[:, :-1, :]\n",
    "            x_lens -= 1\n",
    "\n",
    "        # Reshape x\n",
    "        x = x.view(batch_size, timesteps // 2, features * 2)\n",
    "\n",
    "        # Reduce lengths by half\n",
    "        x_lens = x_lens // 2\n",
    "\n",
    "        return x, x_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa549bee",
   "metadata": {},
   "source": [
    "Introduced class LockedDropout to applies dropout to an entire timestep across the batch, preserving the same dropout mask for all time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc233b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:57.297331Z",
     "iopub.status.busy": "2024-11-08T20:10:57.296853Z",
     "iopub.status.idle": "2024-11-08T20:10:57.304393Z",
     "shell.execute_reply": "2024-11-08T20:10:57.303581Z"
    },
    "papermill": {
     "duration": 0.03132,
     "end_time": "2024-11-08T20:10:57.306330",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.275010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LockedDropout(nn.Module):\n",
    "    def __init__(self, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.dropout == 0:\n",
    "            return x\n",
    "        un_packed, x_lens = pad_packed_sequence(x, batch_first=True)\n",
    "        \n",
    "        # Create a dropout mask\n",
    "        m = x.data.new(1, un_packed.size(1), un_packed.size(2)).bernoulli_(1 - self.dropout)\n",
    "        mask = Variable(m, requires_grad=False) / (1 - self.dropout)\n",
    "        mask = mask.expand_as(un_packed)\n",
    "        \n",
    "        # Apply the mask to the unpacked input\n",
    "        out = mask * un_packed\n",
    "        return pack_padded_sequence(out, lengths=x_lens, batch_first=True, enforce_sorted=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c25bad",
   "metadata": {
    "id": "g3ZQ75OcMUz0",
    "papermill": {
     "duration": 0.021004,
     "end_time": "2024-11-08T20:10:57.349194",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.328190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd1755",
   "metadata": {},
   "source": [
    "Encoder class Consists of embedding layer using convolutions for feature extraction, and multiple layers of pyramidal BiLSTMs (pBLSTMs) that gradually reduce sequence length while maintaining feature complexity, and employs LockedDropout for improved regularization during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed3a9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:57.392926Z",
     "iopub.status.busy": "2024-11-08T20:10:57.392584Z",
     "iopub.status.idle": "2024-11-08T20:10:57.401316Z",
     "shell.execute_reply": "2024-11-08T20:10:57.400423Z"
    },
    "papermill": {
     "duration": 0.032879,
     "end_time": "2024-11-08T20:10:57.403188",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.370309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, encoder_hidden_size, dropout=0.25):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Sequential(\n",
    "            PermuteBlock(),\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=input_size, kernel_size=7, padding=3),\n",
    "            nn.GELU(),\n",
    "            PermuteBlock()\n",
    "        ) #TODO: You can use CNNs as Embedding layer to extract features. Keep in mind the Input dimensions and expected dimension of Pytorch CNN.\n",
    "        \n",
    "        \n",
    "        # How many pBLSTMs are required?\n",
    "            # TODO: Fill this up with pBLSTMs - What should the input_size be?\n",
    "            # Hint: You are downsampling timesteps by a factor of 2, upsampling features by a factor of 2 and the LSTM is bidirectional)\n",
    "            # Optional: Dropout/Locked Dropout after each pBLSTM (Not needed for early submission)\n",
    "            # https://github.com/salesforce/awd-lstm-lm/blob/dfd3cb0235d2caf2847a4d53e1cbd495b781b5d2/locked_dropout.py#L5\n",
    "            # ...\n",
    "            # ...\n",
    "        self.BLSTMs = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=encoder_hidden_size,\n",
    "            num_layers=3, batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.pBLSTMs = nn.Sequential(\n",
    "            LockedDropout(dropout),\n",
    "            pBLSTM(encoder_hidden_size * 2, encoder_hidden_size),\n",
    "            LockedDropout(dropout),\n",
    "            pBLSTM(encoder_hidden_size * 2, encoder_hidden_size)\n",
    "        )\n",
    "        \n",
    "        self.dropout_layer = LockedDropout(dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, x, x_lens):\n",
    "        # Where are x and x_lens coming from? The dataloader\n",
    "        x = self.embedding(x)    #TODO: Call the embedding layer\n",
    "        # TODO: Pack Padded Sequence\n",
    "        x_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        x_packed, (h_n, c_n) = self.BLSTMs(x_packed)\n",
    "        x_packed = self.pBLSTMs(x_packed)\n",
    "        # TODO: Pass Sequence through the pyramidal Bi-LSTM laye\n",
    "        # TODO: Pad Packed Sequence\n",
    "        encoder_outputs, encoder_lens = pad_packed_sequence(x_packed, batch_first=True)\n",
    "        # Remember the number of output(s) each function returns\n",
    "        return encoder_outputs, encoder_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc039f",
   "metadata": {
    "id": "kg82HXa3MUz1",
    "papermill": {
     "duration": 0.020722,
     "end_time": "2024-11-08T20:10:57.444647",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.423925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8755a1f",
   "metadata": {},
   "source": [
    "The Decoder class transforms encoder outputs to phoneme predictions using a multi-layer perceptron (MLP) architecture. This MLP includes layers for batch normalization, GELU activations, and dropout for regularization. The final output is produced by a linear layer followed by a log softmax activation to generate a probability distribution over the possible phonemes, suitable for classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975f8104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:57.487427Z",
     "iopub.status.busy": "2024-11-08T20:10:57.486930Z",
     "iopub.status.idle": "2024-11-08T20:10:57.494991Z",
     "shell.execute_reply": "2024-11-08T20:10:57.494158Z"
    },
    "id": "PQIRxdNTMUz1",
    "papermill": {
     "duration": 0.031324,
     "end_time": "2024-11-08T20:10:57.496824",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.465500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size, output_size= 41, decoder_dropout=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            PermuteBlock(), torch.nn.BatchNorm1d(2*embed_size), PermuteBlock(),\n",
    "            #TODO define your MLP arch. Refer HW1P2\n",
    "            #Use Permute Block before and after BatchNorm1d() to match the size\n",
    "            torch.nn.Linear(2 * embed_size, 2 * embed_size),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(decoder_dropout),\n",
    "            torch.nn.Linear(2 * embed_size, 2 * embed_size),\n",
    "            torch.nn.GELU(),\n",
    "            PermuteBlock(),\n",
    "            torch.nn.BatchNorm1d(2*embed_size), \n",
    "            PermuteBlock(),\n",
    "            torch.nn.Linear(2 * embed_size, embed_size),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(decoder_dropout),\n",
    "            torch.nn.Linear(embed_size, output_size)\n",
    "            )\n",
    "\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, encoder_out):\n",
    "        #TODO call your MLP\n",
    "        mlp_out = self.mlp(encoder_out)\n",
    "        #TODO Think what should be the final output of the decoder for the classification\n",
    "        return self.softmax(mlp_out)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b34690",
   "metadata": {},
   "source": [
    " Automatic Speech Recognition (ASR) network, I included data augmentations such as time and frequency masking to enhance robustness against variations in input data. Additianally, initialized Encoder and Decoder aswell for input processing and produce the final phoneme sequence respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f8eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:57.587015Z",
     "iopub.status.busy": "2024-11-08T20:10:57.586729Z",
     "iopub.status.idle": "2024-11-08T20:10:57.593427Z",
     "shell.execute_reply": "2024-11-08T20:10:57.592637Z"
    },
    "papermill": {
     "duration": 0.030044,
     "end_time": "2024-11-08T20:10:57.595277",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.565233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ASRModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embed_size= 192, output_size= len(PHONEMES)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.augmentations  = torch.nn.Sequential(\n",
    "            #TODO Add Time Masking/ Frequency Masking\n",
    "            T.TimeMasking(time_mask_param=10),\n",
    "            T.FrequencyMasking(freq_mask_param=5)\n",
    "            #Hint: See how to use PermuteBlock() function defined above\n",
    "        )\n",
    "        self.encoder        = Encoder(input_size, embed_size)# TODO: Initialize Encoder\n",
    "        self.decoder        = Decoder(embed_size, output_size)# TODO: Initialize Decoder\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths_x):\n",
    "\n",
    "        if self.training:\n",
    "            x = self.augmentations(x)\n",
    "\n",
    "        encoder_out, encoder_lens   = self.encoder(x, lengths_x)\n",
    "        decoder_out = self.decoder(encoder_out)\n",
    "\n",
    "        return decoder_out, encoder_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55665bc4",
   "metadata": {
    "id": "EV7DMPDoMUz2",
    "papermill": {
     "duration": 0.020519,
     "end_time": "2024-11-08T20:10:57.684518",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.663999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialize ASR Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fc94895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:57.726493Z",
     "iopub.status.busy": "2024-11-08T20:10:57.726228Z",
     "iopub.status.idle": "2024-11-08T20:10:59.827724Z",
     "shell.execute_reply": "2024-11-08T20:10:59.826501Z"
    },
    "id": "oaaDsnnLMUz2",
    "papermill": {
     "duration": 2.125893,
     "end_time": "2024-11-08T20:10:59.830864",
     "exception": false,
     "start_time": "2024-11-08T20:10:57.704971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASRModel(\n",
      "  (augmentations): Sequential(\n",
      "    (0): TimeMasking()\n",
      "    (1): FrequencyMasking()\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Sequential(\n",
      "      (0): PermuteBlock()\n",
      "      (1): Conv1d(28, 28, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): PermuteBlock()\n",
      "    )\n",
      "    (BLSTMs): LSTM(28, 256, num_layers=3, batch_first=True, dropout=0.25, bidirectional=True)\n",
      "    (pBLSTMs): Sequential(\n",
      "      (0): LockedDropout()\n",
      "      (1): pBLSTM(\n",
      "        (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (2): LockedDropout()\n",
      "      (3): pBLSTM(\n",
      "        (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "    (dropout_layer): LockedDropout()\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (mlp): Sequential(\n",
      "      (0): PermuteBlock()\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): PermuteBlock()\n",
      "      (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (4): GELU(approximate='none')\n",
      "      (5): Dropout(p=0.2, inplace=False)\n",
      "      (6): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (7): GELU(approximate='none')\n",
      "      (8): PermuteBlock()\n",
      "      (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): PermuteBlock()\n",
      "      (11): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (12): GELU(approximate='none')\n",
      "      (13): Dropout(p=0.2, inplace=False)\n",
      "      (14): Linear(in_features=256, out_features=41, bias=True)\n",
      "    )\n",
      "    (softmax): LogSoftmax(dim=2)\n",
      "  )\n",
      ")\n",
      "=====================================================================================\n",
      "                                   Kernel Shape    Output Shape     Params  \\\n",
      "Layer                                                                        \n",
      "0_augmentations.TimeMasking_0                 -  [64, 1683, 28]          -   \n",
      "1_augmentations.FrequencyMasking_1            -  [64, 1683, 28]          -   \n",
      "2_encoder.embedding.PermuteBlock_0            -  [64, 28, 1683]          -   \n",
      "3_encoder.embedding.Conv1d_1        [28, 28, 7]  [64, 28, 1683]     5.516k   \n",
      "4_encoder.embedding.GELU_2                    -  [64, 28, 1683]          -   \n",
      "5_encoder.embedding.PermuteBlock_3            -  [64, 1683, 28]          -   \n",
      "6_encoder.LSTM_BLSTMs                         -    [82600, 512]  3.739648M   \n",
      "7_encoder.pBLSTMs.LockedDropout_0             -    [82600, 512]          -   \n",
      "8_encoder.pBLSTMs.1.LSTM_blstm                -    [41252, 512]  2.625536M   \n",
      "9_encoder.pBLSTMs.LockedDropout_2             -    [41252, 512]          -   \n",
      "10_encoder.pBLSTMs.3.LSTM_blstm               -    [20578, 512]  2.625536M   \n",
      "11_decoder.mlp.PermuteBlock_0                 -  [64, 512, 420]          -   \n",
      "12_decoder.mlp.BatchNorm1d_1              [512]  [64, 512, 420]     1.024k   \n",
      "13_decoder.mlp.PermuteBlock_2                 -  [64, 420, 512]          -   \n",
      "14_decoder.mlp.Linear_3              [512, 512]  [64, 420, 512]   262.656k   \n",
      "15_decoder.mlp.GELU_4                         -  [64, 420, 512]          -   \n",
      "16_decoder.mlp.Dropout_5                      -  [64, 420, 512]          -   \n",
      "17_decoder.mlp.Linear_6              [512, 512]  [64, 420, 512]   262.656k   \n",
      "18_decoder.mlp.GELU_7                         -  [64, 420, 512]          -   \n",
      "19_decoder.mlp.PermuteBlock_8                 -  [64, 512, 420]          -   \n",
      "20_decoder.mlp.BatchNorm1d_9              [512]  [64, 512, 420]     1.024k   \n",
      "21_decoder.mlp.PermuteBlock_10                -  [64, 420, 512]          -   \n",
      "22_decoder.mlp.Linear_11             [512, 256]  [64, 420, 256]   131.328k   \n",
      "23_decoder.mlp.GELU_12                        -  [64, 420, 256]          -   \n",
      "24_decoder.mlp.Dropout_13                     -  [64, 420, 256]          -   \n",
      "25_decoder.mlp.Linear_14              [256, 41]   [64, 420, 41]    10.537k   \n",
      "26_decoder.LogSoftmax_softmax                 -   [64, 420, 41]          -   \n",
      "\n",
      "                                    Mult-Adds  \n",
      "Layer                                          \n",
      "0_augmentations.TimeMasking_0               -  \n",
      "1_augmentations.FrequencyMasking_1          -  \n",
      "2_encoder.embedding.PermuteBlock_0          -  \n",
      "3_encoder.embedding.Conv1d_1        9.236304M  \n",
      "4_encoder.embedding.GELU_2                  -  \n",
      "5_encoder.embedding.PermuteBlock_3          -  \n",
      "6_encoder.LSTM_BLSTMs                3.72736M  \n",
      "7_encoder.pBLSTMs.LockedDropout_0           -  \n",
      "8_encoder.pBLSTMs.1.LSTM_blstm       2.62144M  \n",
      "9_encoder.pBLSTMs.LockedDropout_2           -  \n",
      "10_encoder.pBLSTMs.3.LSTM_blstm      2.62144M  \n",
      "11_decoder.mlp.PermuteBlock_0               -  \n",
      "12_decoder.mlp.BatchNorm1d_1            512.0  \n",
      "13_decoder.mlp.PermuteBlock_2               -  \n",
      "14_decoder.mlp.Linear_3              262.144k  \n",
      "15_decoder.mlp.GELU_4                       -  \n",
      "16_decoder.mlp.Dropout_5                    -  \n",
      "17_decoder.mlp.Linear_6              262.144k  \n",
      "18_decoder.mlp.GELU_7                       -  \n",
      "19_decoder.mlp.PermuteBlock_8               -  \n",
      "20_decoder.mlp.BatchNorm1d_9            512.0  \n",
      "21_decoder.mlp.PermuteBlock_10              -  \n",
      "22_decoder.mlp.Linear_11             131.072k  \n",
      "23_decoder.mlp.GELU_12                      -  \n",
      "24_decoder.mlp.Dropout_13                   -  \n",
      "25_decoder.mlp.Linear_14              10.496k  \n",
      "26_decoder.LogSoftmax_softmax               -  \n",
      "-------------------------------------------------------------------------------------\n",
      "                          Totals\n",
      "Total params           9.665461M\n",
      "Trainable params       9.665461M\n",
      "Non-trainable params         0.0\n",
      "Mult-Adds             18.873424M\n",
      "=====================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_augmentations.TimeMasking_0</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 1683, 28]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_augmentations.FrequencyMasking_1</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 1683, 28]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_encoder.embedding.PermuteBlock_0</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 28, 1683]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_encoder.embedding.Conv1d_1</th>\n",
       "      <td>[28, 28, 7]</td>\n",
       "      <td>[64, 28, 1683]</td>\n",
       "      <td>5516.0</td>\n",
       "      <td>9236304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_encoder.embedding.GELU_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 28, 1683]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_encoder.embedding.PermuteBlock_3</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 1683, 28]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_encoder.LSTM_BLSTMs</th>\n",
       "      <td>-</td>\n",
       "      <td>[82600, 512]</td>\n",
       "      <td>3739648.0</td>\n",
       "      <td>3727360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_encoder.pBLSTMs.LockedDropout_0</th>\n",
       "      <td>-</td>\n",
       "      <td>[82600, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_encoder.pBLSTMs.1.LSTM_blstm</th>\n",
       "      <td>-</td>\n",
       "      <td>[41252, 512]</td>\n",
       "      <td>2625536.0</td>\n",
       "      <td>2621440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_encoder.pBLSTMs.LockedDropout_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[41252, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_encoder.pBLSTMs.3.LSTM_blstm</th>\n",
       "      <td>-</td>\n",
       "      <td>[20578, 512]</td>\n",
       "      <td>2625536.0</td>\n",
       "      <td>2621440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_decoder.mlp.PermuteBlock_0</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 512, 420]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_decoder.mlp.BatchNorm1d_1</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[64, 512, 420]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_decoder.mlp.PermuteBlock_2</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 420, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_decoder.mlp.Linear_3</th>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>[64, 420, 512]</td>\n",
       "      <td>262656.0</td>\n",
       "      <td>262144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_decoder.mlp.GELU_4</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 420, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_decoder.mlp.Dropout_5</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 420, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_decoder.mlp.Linear_6</th>\n",
       "      <td>[512, 512]</td>\n",
       "      <td>[64, 420, 512]</td>\n",
       "      <td>262656.0</td>\n",
       "      <td>262144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_decoder.mlp.GELU_7</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 420, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19_decoder.mlp.PermuteBlock_8</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 512, 420]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_decoder.mlp.BatchNorm1d_9</th>\n",
       "      <td>[512]</td>\n",
       "      <td>[64, 512, 420]</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21_decoder.mlp.PermuteBlock_10</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 420, 512]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22_decoder.mlp.Linear_11</th>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>[64, 420, 256]</td>\n",
       "      <td>131328.0</td>\n",
       "      <td>131072.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23_decoder.mlp.GELU_12</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 420, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_decoder.mlp.Dropout_13</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 420, 256]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_decoder.mlp.Linear_14</th>\n",
       "      <td>[256, 41]</td>\n",
       "      <td>[64, 420, 41]</td>\n",
       "      <td>10537.0</td>\n",
       "      <td>10496.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_decoder.LogSoftmax_softmax</th>\n",
       "      <td>-</td>\n",
       "      <td>[64, 420, 41]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Kernel Shape    Output Shape     Params  \\\n",
       "Layer                                                                        \n",
       "0_augmentations.TimeMasking_0                 -  [64, 1683, 28]        NaN   \n",
       "1_augmentations.FrequencyMasking_1            -  [64, 1683, 28]        NaN   \n",
       "2_encoder.embedding.PermuteBlock_0            -  [64, 28, 1683]        NaN   \n",
       "3_encoder.embedding.Conv1d_1        [28, 28, 7]  [64, 28, 1683]     5516.0   \n",
       "4_encoder.embedding.GELU_2                    -  [64, 28, 1683]        NaN   \n",
       "5_encoder.embedding.PermuteBlock_3            -  [64, 1683, 28]        NaN   \n",
       "6_encoder.LSTM_BLSTMs                         -    [82600, 512]  3739648.0   \n",
       "7_encoder.pBLSTMs.LockedDropout_0             -    [82600, 512]        NaN   \n",
       "8_encoder.pBLSTMs.1.LSTM_blstm                -    [41252, 512]  2625536.0   \n",
       "9_encoder.pBLSTMs.LockedDropout_2             -    [41252, 512]        NaN   \n",
       "10_encoder.pBLSTMs.3.LSTM_blstm               -    [20578, 512]  2625536.0   \n",
       "11_decoder.mlp.PermuteBlock_0                 -  [64, 512, 420]        NaN   \n",
       "12_decoder.mlp.BatchNorm1d_1              [512]  [64, 512, 420]     1024.0   \n",
       "13_decoder.mlp.PermuteBlock_2                 -  [64, 420, 512]        NaN   \n",
       "14_decoder.mlp.Linear_3              [512, 512]  [64, 420, 512]   262656.0   \n",
       "15_decoder.mlp.GELU_4                         -  [64, 420, 512]        NaN   \n",
       "16_decoder.mlp.Dropout_5                      -  [64, 420, 512]        NaN   \n",
       "17_decoder.mlp.Linear_6              [512, 512]  [64, 420, 512]   262656.0   \n",
       "18_decoder.mlp.GELU_7                         -  [64, 420, 512]        NaN   \n",
       "19_decoder.mlp.PermuteBlock_8                 -  [64, 512, 420]        NaN   \n",
       "20_decoder.mlp.BatchNorm1d_9              [512]  [64, 512, 420]     1024.0   \n",
       "21_decoder.mlp.PermuteBlock_10                -  [64, 420, 512]        NaN   \n",
       "22_decoder.mlp.Linear_11             [512, 256]  [64, 420, 256]   131328.0   \n",
       "23_decoder.mlp.GELU_12                        -  [64, 420, 256]        NaN   \n",
       "24_decoder.mlp.Dropout_13                     -  [64, 420, 256]        NaN   \n",
       "25_decoder.mlp.Linear_14              [256, 41]   [64, 420, 41]    10537.0   \n",
       "26_decoder.LogSoftmax_softmax                 -   [64, 420, 41]        NaN   \n",
       "\n",
       "                                    Mult-Adds  \n",
       "Layer                                          \n",
       "0_augmentations.TimeMasking_0             NaN  \n",
       "1_augmentations.FrequencyMasking_1        NaN  \n",
       "2_encoder.embedding.PermuteBlock_0        NaN  \n",
       "3_encoder.embedding.Conv1d_1        9236304.0  \n",
       "4_encoder.embedding.GELU_2                NaN  \n",
       "5_encoder.embedding.PermuteBlock_3        NaN  \n",
       "6_encoder.LSTM_BLSTMs               3727360.0  \n",
       "7_encoder.pBLSTMs.LockedDropout_0         NaN  \n",
       "8_encoder.pBLSTMs.1.LSTM_blstm      2621440.0  \n",
       "9_encoder.pBLSTMs.LockedDropout_2         NaN  \n",
       "10_encoder.pBLSTMs.3.LSTM_blstm     2621440.0  \n",
       "11_decoder.mlp.PermuteBlock_0             NaN  \n",
       "12_decoder.mlp.BatchNorm1d_1            512.0  \n",
       "13_decoder.mlp.PermuteBlock_2             NaN  \n",
       "14_decoder.mlp.Linear_3              262144.0  \n",
       "15_decoder.mlp.GELU_4                     NaN  \n",
       "16_decoder.mlp.Dropout_5                  NaN  \n",
       "17_decoder.mlp.Linear_6              262144.0  \n",
       "18_decoder.mlp.GELU_7                     NaN  \n",
       "19_decoder.mlp.PermuteBlock_8             NaN  \n",
       "20_decoder.mlp.BatchNorm1d_9            512.0  \n",
       "21_decoder.mlp.PermuteBlock_10            NaN  \n",
       "22_decoder.mlp.Linear_11             131072.0  \n",
       "23_decoder.mlp.GELU_12                    NaN  \n",
       "24_decoder.mlp.Dropout_13                 NaN  \n",
       "25_decoder.mlp.Linear_14              10496.0  \n",
       "26_decoder.LogSoftmax_softmax             NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ASRModel(\n",
    "    input_size  = 28, #TODO,\n",
    "    embed_size  = 256, #TODO\n",
    "    output_size = len(PHONEMES)\n",
    ").to(device)\n",
    "print(model)\n",
    "summary(model, x.to(device), lx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43fdd6",
   "metadata": {
    "id": "IBwunYpyugFg",
    "papermill": {
     "duration": 0.021188,
     "end_time": "2024-11-08T20:10:59.924732",
     "exception": false,
     "start_time": "2024-11-08T20:10:59.903544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Config\n",
    "Initialize Loss Criterion, Optimizer, CTC Beam Decoder, Scheduler, Scaler (Mixed-Precision), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f76d0",
   "metadata": {},
   "source": [
    "Initializing loss function criterion using  CTCLOss, and for this task I used AdamW as the optimizer where i tuned paramater like learning rate, and weight decay. For scheduler I used CosineAnnealingLR, ReduceLROnPlateau, and stepLR. Decoder I implemented CTCBeamDecoder to enhance the preduction accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a1e6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:10:59.968673Z",
     "iopub.status.busy": "2024-11-08T20:10:59.968099Z",
     "iopub.status.idle": "2024-11-08T20:10:59.975160Z",
     "shell.execute_reply": "2024-11-08T20:10:59.974228Z"
    },
    "id": "iGoozH2nd6KB",
    "papermill": {
     "duration": 0.031165,
     "end_time": "2024-11-08T20:10:59.977149",
     "exception": false,
     "start_time": "2024-11-08T20:10:59.945984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "criterion = nn.CTCLoss(blank= CMUdict.index('')) # Define CTC loss as the criterion. How would the losses be reduced?\n",
    "# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
    "# Refer to the handout for hints\n",
    "\n",
    "optimizer =  torch.optim.AdamW(model.parameters(), lr=config['lr']) # What goes in here?\n",
    "\n",
    "# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n",
    "# CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
    "decoder = CTCBeamDecoder(labels=LABELS,\n",
    "                         beam_width=3,\n",
    "                         num_processes= 1,\n",
    "                         log_probs_input=True) #TODO\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "#                                                        mode= 'min',\n",
    "#                                                        factor= 0.5,\n",
    "#                                                        patience= 3,\n",
    "#                                                        threshold= 1e-3,\n",
    "#                                                        verbose=True)#TODO\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])\n",
    "\n",
    "\n",
    "\n",
    "# Mixed Precision, if you need it\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a61fec",
   "metadata": {
    "id": "Jmc6_4eWL2Xp",
    "papermill": {
     "duration": 0.021582,
     "end_time": "2024-11-08T20:11:00.020042",
     "exception": false,
     "start_time": "2024-11-08T20:10:59.998460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decode Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a5597",
   "metadata": {},
   "source": [
    "Decode prediction The function that decodes the output predictions from the model using a CTCBeamDecoder.\n",
    "\n",
    "Calculate levenshtein method, the function for calculating the average Levenshtein distance, which measures the edit distance between predicted phoneme sequences and the ground truth labels across a batch. Which is used to evaluate the model's performance by quantifying how many insertions, deletions, or substitutions are required to convert the predicted sequences into the actual phoneme sequences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2b755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:11:00.063904Z",
     "iopub.status.busy": "2024-11-08T20:11:00.063524Z",
     "iopub.status.idle": "2024-11-08T20:11:00.072656Z",
     "shell.execute_reply": "2024-11-08T20:11:00.071823Z"
    },
    "id": "KHjnCDddL36E",
    "papermill": {
     "duration": 0.033289,
     "end_time": "2024-11-08T20:11:00.074464",
     "exception": false,
     "start_time": "2024-11-08T20:11:00.041175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_prediction(output, output_lens, decoder, PHONEME_MAP= LABELS):\n",
    "\n",
    "    # TODO: look at docs for CTC.decoder and find out what is returned here. Check the shape of output and expected shape in decode.\n",
    "    output = torch.transpose(output, 0, 1)\n",
    "    output, _, _, out_seq_len = decoder.decode(output, seq_lens= output_lens) #lengths - list of lengths\n",
    "\n",
    "    pred_strings = []\n",
    "\n",
    "    for i in range(output_lens.shape[0]):\n",
    "        #TODO: Create the prediction from the output of decoder.decode. Don't forget to map it using PHONEMES_MAP.\n",
    "        logits=output[i][0][:out_seq_len[i][0]]\n",
    "        try:\n",
    "            pred_strings.append(''.join([PHONEME_MAP[i] for i in logits]))\n",
    "        except:\n",
    "            print(logits)\n",
    "            \n",
    "    return pred_strings\n",
    "\n",
    "def calculate_levenshtein(output, label, output_lens, label_lens, decoder, PHONEME_MAP= LABELS): # y - sequence of integers\n",
    "\n",
    "    dist            = 0\n",
    "    batch_size      = label.shape[0]\n",
    "\n",
    "    pred_strings    = decode_prediction(output, output_lens, decoder, PHONEME_MAP)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        # TODO: Get predicted string and label string for each element in the batch\n",
    "        pred_string = pred_strings[i]   # TODO\n",
    "        label_string = ''.join(PHONEME_MAP[l] for l in label[i][:label_lens[i]]) #TODO\n",
    "        dist += Levenshtein.distance(pred_string, label_string)\n",
    "\n",
    "    dist /= batch_size # TODO: Uncomment this, but think about why we are doing this\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d89072",
   "metadata": {
    "id": "0Qk9iZud1LXT",
    "papermill": {
     "duration": 0.021295,
     "end_time": "2024-11-08T20:11:00.117032",
     "exception": false,
     "start_time": "2024-11-08T20:11:00.095737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54555024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:11:00.161308Z",
     "iopub.status.busy": "2024-11-08T20:11:00.160519Z",
     "iopub.status.idle": "2024-11-08T20:11:01.749043Z",
     "shell.execute_reply": "2024-11-08T20:11:01.747862Z"
    },
    "id": "GnTLL-5gMBrY",
    "papermill": {
     "duration": 1.613056,
     "end_time": "2024-11-08T20:11:01.751273",
     "exception": false,
     "start_time": "2024-11-08T20:11:00.138217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 811, 41])\n",
      "torch.Size([811, 64, 41]) torch.Size([64, 360])\n",
      "tensor(7.1916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "229.65625\n"
     ]
    }
   ],
   "source": [
    "# test code to check shapes\n",
    "\n",
    "model.eval()\n",
    "for i, data in enumerate(val_loader, 0):\n",
    "    x, y, lx, ly = data\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    h, lh = model(x, lx)\n",
    "    print(h.shape)\n",
    "    h = torch.permute(h, (1, 0, 2))\n",
    "    print(h.shape, y.shape)\n",
    "    loss = criterion(h, y, lh, ly)\n",
    "    print(loss)\n",
    "\n",
    "    print(calculate_levenshtein(h, y, lx, ly, decoder, LABELS))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9949d39",
   "metadata": {
    "id": "rd5aNaLVoR_g",
    "papermill": {
     "duration": 0.021568,
     "end_time": "2024-11-08T20:11:01.795367",
     "exception": false,
     "start_time": "2024-11-08T20:11:01.773799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# WandB\n",
    "\n",
    "You will need to fetch your api key from wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4710677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:11:01.840934Z",
     "iopub.status.busy": "2024-11-08T20:11:01.840398Z",
     "iopub.status.idle": "2024-11-08T20:11:03.258495Z",
     "shell.execute_reply": "2024-11-08T20:11:03.257563Z"
    },
    "id": "PiDduMaDIARE",
    "papermill": {
     "duration": 1.443455,
     "end_time": "2024-11-08T20:11:03.260428",
     "exception": false,
     "start_time": "2024-11-08T20:11:01.816973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"65ab01e861811be49c0d4f76312a0729eb26cdfc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419f12bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec885df8",
   "metadata": {},
   "source": [
    "Here is the link to the wandb to visualize the runs that I did unfortunetly my trial for wandb has expired and force me to downgrade to 5GB storage and I tried to delete some runs to free up space. Here is the link to see my run Url: https://wandb.ai/angeizabayo05-carnegie-mellon-university, run_id that gave me the high cutoff **fqxhsk3w**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dd14c2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:11:03.307113Z",
     "iopub.status.busy": "2024-11-08T20:11:03.306789Z",
     "iopub.status.idle": "2024-11-08T20:11:06.483315Z",
     "shell.execute_reply": "2024-11-08T20:11:06.482065Z"
    },
    "id": "4s52yBOvICPZ",
    "papermill": {
     "duration": 3.202925,
     "end_time": "2024-11-08T20:11:06.486406",
     "exception": false,
     "start_time": "2024-11-08T20:11:03.283481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mangeizabayo05\u001b[0m (\u001b[33mangeizabayo05-carnegie-mellon-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241108_201103-fqxhsk3w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mNew_run_submission-08-11-2022_50Epoch\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/angeizabayo05-carnegie-mellon-university/hw3p2-ablations\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/angeizabayo05-carnegie-mellon-university/hw3p2-ablations/runs/fqxhsk3w\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    name = \"New_run_submission-08-11-2022_50Epoch\", ## Wandb creates random run names if you skip this field\n",
    "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
    "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"hw3p2-ablations\", ### Project should be created in your wandb account\n",
    "    config = config ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd40f43",
   "metadata": {
    "id": "6fLLj5KIMMOe",
    "papermill": {
     "duration": 0.027743,
     "end_time": "2024-11-08T20:11:06.540543",
     "exception": false,
     "start_time": "2024-11-08T20:11:06.512800",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90586657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:11:06.596856Z",
     "iopub.status.busy": "2024-11-08T20:11:06.596462Z",
     "iopub.status.idle": "2024-11-08T20:11:06.613651Z",
     "shell.execute_reply": "2024-11-08T20:11:06.612639Z"
    },
    "id": "ri87MAdhMUz5",
    "papermill": {
     "duration": 0.047902,
     "end_time": "2024-11-08T20:11:06.615779",
     "exception": false,
     "start_time": "2024-11-08T20:11:06.567877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y, lx, ly = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            h, lh = model(x, lx)\n",
    "            h = torch.permute(h, (1, 0, 2))\n",
    "            loss = criterion(h, y, lh, ly)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "\n",
    "        batch_bar.update() # Update tqdm bar\n",
    "\n",
    "        # Another couple things you need for FP16.\n",
    "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
    "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
    "        scaler.update() # This is something added just for FP16\n",
    "\n",
    "        del x, y, lx, ly, h, lh, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close() # You need this to close the tqdm bar\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate_model(model, val_loader, decoder, phoneme_map= LABELS):\n",
    "\n",
    "    model.eval()\n",
    "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "\n",
    "    total_loss = 0\n",
    "    vdist = 0\n",
    "\n",
    "    for i, data in enumerate(val_loader):\n",
    "\n",
    "        x, y, lx, ly = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            h, lh = model(x, lx)\n",
    "            h = torch.permute(h, (1, 0, 2))\n",
    "            loss = criterion(h, y, lh, ly)\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        vdist += calculate_levenshtein(h, y, lh, ly, decoder, phoneme_map)\n",
    "\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
    "\n",
    "        batch_bar.update()\n",
    "\n",
    "        del x, y, lx, ly, h, lh, loss\n",
    "        torch.cuda.empty_cache()\n",
    " \n",
    "    batch_bar.close() #close the progress bar\n",
    "    total_loss = total_loss/len(val_loader)\n",
    "    val_dist = vdist/len(val_loader)\n",
    "    return total_loss,val_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a818aa91",
   "metadata": {
    "id": "qpYExu4vT4_g",
    "papermill": {
     "duration": 0.022989,
     "end_time": "2024-11-08T20:11:06.664838",
     "exception": false,
     "start_time": "2024-11-08T20:11:06.641849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e0559a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:11:06.711930Z",
     "iopub.status.busy": "2024-11-08T20:11:06.711625Z",
     "iopub.status.idle": "2024-11-08T20:11:06.718478Z",
     "shell.execute_reply": "2024-11-08T20:11:06.717757Z"
    },
    "id": "husa5_EYMUz6",
    "papermill": {
     "duration": 0.032398,
     "end_time": "2024-11-08T20:11:06.720268",
     "exception": false,
     "start_time": "2024-11-08T20:11:06.687870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
    "    torch.save(\n",
    "        {'model_state_dict'         : model.state_dict(),\n",
    "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
    "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
    "         metric[0]                  : metric[1],\n",
    "         'epoch'                    : epoch},\n",
    "         path\n",
    "    )\n",
    "\n",
    "def load_model(path, model, metric= 'valid_acc', optimizer= None, scheduler= None):\n",
    "\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    if optimizer != None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler != None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    epoch   = checkpoint['epoch']\n",
    "    metric  = checkpoint[metric]\n",
    "\n",
    "    return [model, optimizer, scheduler, epoch, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc7970fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:11:06.767074Z",
     "iopub.status.busy": "2024-11-08T20:11:06.766813Z",
     "iopub.status.idle": "2024-11-08T20:11:06.772337Z",
     "shell.execute_reply": "2024-11-08T20:11:06.771657Z"
    },
    "id": "tExvyl1BIdMC",
    "papermill": {
     "duration": 0.030852,
     "end_time": "2024-11-08T20:11:06.774093",
     "exception": false,
     "start_time": "2024-11-08T20:11:06.743241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_model_path = '/kaggle/working/epoch_model.pth'#TODO set the model path( Optional, you can just store best one. Make sure to make the changes below )\n",
    "best_model_path = '/kaggle/working/best_model.pth'#TODO set best model path# This is for checkpointing, if you're doing it over multiple sessions\n",
    "\n",
    "last_epoch_completed = 0\n",
    "start = last_epoch_completed\n",
    "end = config[\"epochs\"]\n",
    "best_lev_dist = float(\"inf\") # if you're restarting from some checkpoint, use what you saw there.\n",
    "\n",
    "# Set paths for saving models\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Define the model paths\n",
    "epoch_model_path = '/kaggle/working/epoch_model.pth'#TODO set the model path( Optional, you can just store best one. Make sure to make the changes below )\n",
    "best_model_path = '/kaggle/working/best_model.pth'#TODO set best model path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ccd69d",
   "metadata": {},
   "source": [
    "For training loop, I change the above hyperparameter in config dictionary and Scheduler to get the required validation where i started with ReduceLROnPlateau which gave me low cutoff and not working and change to CosineAnnealingLR and tried StepLR as well but it was not perform well as well.\n",
    "\n",
    "I changed the learning rate from given 2e-3 to 1e-3\n",
    "Used Batch size of 64, 32\n",
    "for scheduler used the T-max equal to the number of epoch\n",
    "for encoder I used dropout and decoder function of 0.25\n",
    "\n",
    "\n",
    "for this work training loop  save and display the training loss, validation loss, and validation distance, where I saved the checkpoint and best model in wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bda5b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T20:11:06.822297Z",
     "iopub.status.busy": "2024-11-08T20:11:06.822016Z",
     "iopub.status.idle": "2024-11-09T02:48:33.400882Z",
     "shell.execute_reply": "2024-11-09T02:48:33.399684Z"
    },
    "id": "JR43E28rM9Ak",
    "papermill": {
     "duration": 23846.60639,
     "end_time": "2024-11-09T02:48:33.403577",
     "exception": false,
     "start_time": "2024-11-08T20:11:06.797187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 2.2528\t Learning Rate 0.0010000\n",
      "\tVal Dist 24.7807%\t Val Loss 1.0999\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.9800\t Learning Rate 0.0009990\n",
      "\tVal Dist 14.1904%\t Val Loss 0.6371\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.7444\t Learning Rate 0.0009961\n",
      "\tVal Dist 12.1007%\t Val Loss 0.5392\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.6104\t Learning Rate 0.0009911\n",
      "\tVal Dist 10.3045%\t Val Loss 0.4590\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.5549\t Learning Rate 0.0009843\n",
      "\tVal Dist 9.0909%\t Val Loss 0.4137\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.5089\t Learning Rate 0.0009755\n",
      "\tVal Dist 9.6780%\t Val Loss 0.4421\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4643\t Learning Rate 0.0009649\n",
      "\tVal Dist 8.2845%\t Val Loss 0.3783\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4008\t Learning Rate 0.0009524\n",
      "\tVal Dist 7.4002%\t Val Loss 0.3443\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.4199\t Learning Rate 0.0009382\n",
      "\tVal Dist 7.1127%\t Val Loss 0.3310\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3513\t Learning Rate 0.0009222\n",
      "\tVal Dist 6.7087%\t Val Loss 0.3142\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3510\t Learning Rate 0.0009045\n",
      "\tVal Dist 7.0005%\t Val Loss 0.3248\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3428\t Learning Rate 0.0008853\n",
      "\tVal Dist 6.4772%\t Val Loss 0.3058\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3304\t Learning Rate 0.0008645\n",
      "\tVal Dist 6.3117%\t Val Loss 0.2942\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3072\t Learning Rate 0.0008423\n",
      "\tVal Dist 6.2422%\t Val Loss 0.2973\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.3038\t Learning Rate 0.0008187\n",
      "\tVal Dist 6.6150%\t Val Loss 0.3135\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2960\t Learning Rate 0.0007939\n",
      "\tVal Dist 6.2895%\t Val Loss 0.2986\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2677\t Learning Rate 0.0007679\n",
      "\tVal Dist 5.8788%\t Val Loss 0.2810\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2541\t Learning Rate 0.0007409\n",
      "\tVal Dist 5.8165%\t Val Loss 0.2793\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2502\t Learning Rate 0.0007129\n",
      "\tVal Dist 5.6563%\t Val Loss 0.2726\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2317\t Learning Rate 0.0006841\n",
      "\tVal Dist 5.6025%\t Val Loss 0.2725\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2255\t Learning Rate 0.0006545\n",
      "\tVal Dist 5.4409%\t Val Loss 0.2683\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2231\t Learning Rate 0.0006243\n",
      "\tVal Dist 5.5275%\t Val Loss 0.2703\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2260\t Learning Rate 0.0005937\n",
      "\tVal Dist 5.3433%\t Val Loss 0.2607\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.2094\t Learning Rate 0.0005627\n",
      "\tVal Dist 5.2871%\t Val Loss 0.2605\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1879\t Learning Rate 0.0005314\n",
      "\tVal Dist 5.2204%\t Val Loss 0.2575\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1929\t Learning Rate 0.0005000\n",
      "\tVal Dist 5.1398%\t Val Loss 0.2580\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1780\t Learning Rate 0.0004686\n",
      "\tVal Dist 5.0680%\t Val Loss 0.2552\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1904\t Learning Rate 0.0004373\n",
      "\tVal Dist 5.0042%\t Val Loss 0.2510\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1742\t Learning Rate 0.0004063\n",
      "\tVal Dist 4.9506%\t Val Loss 0.2461\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1715\t Learning Rate 0.0003757\n",
      "\tVal Dist 4.8540%\t Val Loss 0.2490\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1543\t Learning Rate 0.0003455\n",
      "\tVal Dist 5.0199%\t Val Loss 0.2530\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1596\t Learning Rate 0.0003159\n",
      "\tVal Dist 4.8854%\t Val Loss 0.2539\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1493\t Learning Rate 0.0002871\n",
      "\tVal Dist 4.8314%\t Val Loss 0.2519\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1438\t Learning Rate 0.0002591\n",
      "\tVal Dist 4.8261%\t Val Loss 0.2547\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1387\t Learning Rate 0.0002321\n",
      "\tVal Dist 4.7272%\t Val Loss 0.2506\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1344\t Learning Rate 0.0002061\n",
      "\tVal Dist 4.7058%\t Val Loss 0.2480\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1318\t Learning Rate 0.0001813\n",
      "\tVal Dist 4.7392%\t Val Loss 0.2544\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1246\t Learning Rate 0.0001577\n",
      "\tVal Dist 4.6507%\t Val Loss 0.2519\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1287\t Learning Rate 0.0001355\n",
      "\tVal Dist 4.6424%\t Val Loss 0.2486\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1177\t Learning Rate 0.0001147\n",
      "\tVal Dist 4.5924%\t Val Loss 0.2530\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1182\t Learning Rate 0.0000955\n",
      "\tVal Dist 4.6555%\t Val Loss 0.2554\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1151\t Learning Rate 0.0000778\n",
      "\tVal Dist 4.5745%\t Val Loss 0.2565\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1087\t Learning Rate 0.0000618\n",
      "\tVal Dist 4.6099%\t Val Loss 0.2588\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1166\t Learning Rate 0.0000476\n",
      "\tVal Dist 4.5585%\t Val Loss 0.2495\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1120\t Learning Rate 0.0000351\n",
      "\tVal Dist 4.5719%\t Val Loss 0.2585\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1173\t Learning Rate 0.0000245\n",
      "\tVal Dist 4.5296%\t Val Loss 0.2549\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1147\t Learning Rate 0.0000157\n",
      "\tVal Dist 4.5161%\t Val Loss 0.2541\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1085\t Learning Rate 0.0000089\n",
      "\tVal Dist 4.4684%\t Val Loss 0.2525\n",
      "Saved epoch model\n",
      "Saved best model\n",
      "\n",
      "Epoch: 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1101\t Learning Rate 0.0000039\n",
      "\tVal Dist 4.5405%\t Val Loss 0.2493\n",
      "Saved epoch model\n",
      "\n",
      "Epoch: 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss 0.1036\t Learning Rate 0.0000010\n",
      "\tVal Dist 4.5023%\t Val Loss 0.2550\n",
      "Saved epoch model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ████████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_dist █▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_loss █▄▃▃▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.10363\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_dist 4.50225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: valid_loss 0.25504\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mNew_run_submission-08-11-2022_50Epoch\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/angeizabayo05-carnegie-mellon-university/hw3p2-ablations/runs/fqxhsk3w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/angeizabayo05-carnegie-mellon-university/hw3p2-ablations\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241108_201103-fqxhsk3w/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "#TODO: Please complete the training loop\n",
    "\n",
    "for epoch in range(0, config['epochs']):\n",
    "\n",
    "    print(\"\\nEpoch: {}/{}\".format(epoch+1, config['epochs']))\n",
    "\n",
    "    curr_lr = float(optimizer.param_groups[0]['lr']) #TODO\n",
    "\n",
    "    train_loss              = train_model(model, train_loader, criterion, optimizer)#TODO\n",
    "    valid_loss, valid_dist  = validate_model(model, val_loader, decoder, phoneme_map= LABELS)#TODO\n",
    "#     scheduler.step(valid_dist)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n",
    "    print(\"\\tVal Dist {:.04f}%\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n",
    "\n",
    "\n",
    "    wandb.log({\n",
    "        'train_loss': train_loss,\n",
    "        'valid_dist': valid_dist,\n",
    "        'valid_loss': valid_loss,\n",
    "        'lr'        : curr_lr\n",
    "    })\n",
    "\n",
    "    save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, epoch_model_path)\n",
    "    wandb.save(epoch_model_path)\n",
    "    print(\"Saved epoch model\")\n",
    "\n",
    "    if valid_dist <= best_lev_dist:\n",
    "        best_lev_dist = valid_dist\n",
    "        save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, best_model_path)\n",
    "        wandb.save(best_model_path)\n",
    "        print(\"Saved best model\")\n",
    "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db098174",
   "metadata": {
    "id": "M2H4EEj-sD32",
    "papermill": {
     "duration": 4.013859,
     "end_time": "2024-11-09T02:48:41.419084",
     "exception": false,
     "start_time": "2024-11-09T02:48:37.405225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate Predictions and Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdf28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T02:48:49.532067Z",
     "iopub.status.busy": "2024-11-09T02:48:49.530867Z",
     "iopub.status.idle": "2024-11-09T02:49:25.372240Z",
     "shell.execute_reply": "2024-11-09T02:49:25.371172Z"
    },
    "id": "2moYJhTWsOG-",
    "papermill": {
     "duration": 40.175302,
     "end_time": "2024-11-09T02:49:25.630577",
     "exception": false,
     "start_time": "2024-11-09T02:48:45.455275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:35<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#TODO: Make predictions\n",
    "\n",
    "# Follow the steps below:\n",
    "# 1. Create a new object for CTCBeamDecoder with larger (why?) number of beams\n",
    "# 2. Get prediction string by decoding the results of the beam decoder\n",
    "\n",
    "\n",
    "\n",
    "TEST_BEAM_WIDTH = 20 #TODO\n",
    "\n",
    "test_decoder    = CTCBeamDecoder(labels=LABELS, beam_width=TEST_BEAM_WIDTH, log_probs_input=True)#TODO\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "print(\"Testing\")\n",
    "for data in tqdm(test_loader):\n",
    "\n",
    "    x, lx   = data\n",
    "    x       = x.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h, lh = model(x, lx)\n",
    "        h = torch.permute(h, (1, 0, 2))\n",
    "    prediction_string= decode_prediction(h, lh, test_decoder, LABELS)# TODO call decode_prediction\n",
    "    #TODO save the output in results array.\n",
    "    results.extend(prediction_string)\n",
    "\n",
    "    del x, lx, h, lh\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427578a4",
   "metadata": {},
   "source": [
    "Generate the csv file of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac71c073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T02:49:33.735213Z",
     "iopub.status.busy": "2024-11-09T02:49:33.734112Z",
     "iopub.status.idle": "2024-11-09T02:49:33.786235Z",
     "shell.execute_reply": "2024-11-09T02:49:33.785503Z"
    },
    "id": "d70dvu_lsMlv",
    "papermill": {
     "duration": 4.055198,
     "end_time": "2024-11-09T02:49:33.788288",
     "exception": false,
     "start_time": "2024-11-09T02:49:29.733090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"/kaggle/input/random-sub/random_submission.csv\"\n",
    "df = pd.read_csv(data_dir)\n",
    "df.label = results\n",
    "\n",
    "df.to_csv('submission_8_50Epoch.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d746ae28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T02:49:41.930293Z",
     "iopub.status.busy": "2024-11-09T02:49:41.929947Z",
     "iopub.status.idle": "2024-11-09T02:49:44.649822Z",
     "shell.execute_reply": "2024-11-09T02:49:44.648646Z"
    },
    "id": "m1sZmEIs4yIz",
    "papermill": {
     "duration": 6.72006,
     "end_time": "2024-11-09T02:49:44.652197",
     "exception": false,
     "start_time": "2024-11-09T02:49:37.932137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.5.8)\r\n",
      "100%|████████████████████████████████████████| 209k/209k [00:00<00:00, 1.16MB/s]\r\n",
      "Successfully submitted to Automatic Speech Recognition (ASR)"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c 11-785-hw3p2-f24 -f submission_8_50Epoch.csv -m \"I made it!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bab5c",
   "metadata": {
    "papermill": {
     "duration": 3.970297,
     "end_time": "2024-11-09T02:49:52.722191",
     "exception": false,
     "start_time": "2024-11-09T02:49:48.751894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "rd5aNaLVoR_g"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9982962,
     "sourceId": 87560,
     "sourceType": "competition"
    },
    {
     "datasetId": 5994482,
     "sourceId": 9784116,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 25130.675297,
   "end_time": "2024-11-09T02:49:59.527222",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-08T19:51:08.851925",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
